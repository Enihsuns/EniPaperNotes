# SNIPER: Efficient Multi-Scale Training

*Singh B, Najibi M, Davis L S. SNIPER: Efficient multi-scale training[C]//Advances in Neural Information Processing Systems. 2018: 9333-9343.*

> 参考 https://arleyzhang.github.io/articles/f0c1556d/ 和Najibi M的lecture

## Recap & Background
### R-CNN
Procedure:
1. Input image
2. Extract region proposals (~2k): 使用传统的CV方法 直接warp regions到224x224
3. Compute CNN features
4. Classify regions

优点：R-CNN is scale invariant.

缺点：(1)Very slow (2)Limited Context（比如background会被crop掉）

### Fast R-CNN
CNN计算global feature

candidate region

缺点：not scale-invariant

### Scale: Classification vs. Detection
Relative Scale = sqrt(Object Area)/sqrt(Image Area)

Scale variation is more significant in object detection conpared to classification. (通过比较ImageNet和COCO中的图)

### Architectural Changes to Deal with Scale
- Changing final convolutions to improve the resolution: Dilated/Deformable Convolutions
- Using Intermediate Feature Maps
- Scale specific training: only backpropagate for objects which are "relevant" for that scale

## Follow the paper structure
### Abstract
*SNIPER*, an algorithm for performing efficient multi-scale training in instance level visual recognition tasks. 用于在实例级视觉识别任务中执行有效的多尺度训练的算法。主要是用来提高训练的效率，测试的步骤和原来是一样的。

chips: context regions around ground-truth instances

SNIPER不是一个一个像素地处理，而是按照chip处理。

### 1. Introduction
提出问题：trade-off between computation, context and negative mining while accelerating multi-scale training
1. 在解决scale的问题上，Multi-scale training的方法与直接调整CNN结构的方法相比，要慢很多: Faster-RCNN/Mask-RCNN在构建multi-scale image pyramid后，对于每一个scale上的每一个像素都会处理，因此大大增加训练时间。
2. Scale-specific gradient back-propagation: Ignoring gradients of objects which are of extreme resolutions is beneficial while using multiple scales during training（比方说在large resolution的时候，应该忽略large objects） -> 是否需要以3x resulotion来处理整张图？(??) 在inference期间，resampling图片之后，CNN不够robust。

We sample positive chips conditioned on the ground-truth instances and negative chips based on proposals generated by a region proposal network.

### 3. SNIPER
#### 3.1 Chip Generation
SNIPER会在多个scales上生成chips。

对于每一个scale $s_i$，首先图片会被缩放到宽$W_i$和高$H_i$。之后，$K \times K$的chip会被以间隔为$d$的方式摆放。这样的话，每一个scale都将对应一个二维的chips数组。

#### 3.2 Positive Chip Selection
每一个scale都有一个期望的范围$R^i$。这个范围决定了哪一些ground-truth box/proposal要被用来训练。在$$R^i$$范围内的这种box所组成的list被记作$G^i$。然后，使用贪心来选择使得被覆盖的box尽可能多的chip。所有的来自同一个scale的chip被记作$C^i_{pos}$。

这样一来，每一个ground-truth box都得到了合适的scale的覆盖。由于crop-size比图像分辨率小得多(??)，SNIPER不会以高分辨率处理背景，因而节省计算和内存资源。

#### 3.3 Negative Chip Selection
Region Proposal Network (RPN)

首先，移去所有已经在positive chip selection中覆盖的proposal。然后，贪心选择至少覆盖了M个proposal的chips。这些chip组在一起，记作$C^i_{neg}$。

Reduce False Positives: 在已有的训练方法中不会存在FP过高的问题，因为所有的像素都被处理了。

## Basic concepts
image pyramid
region proposal network

## AutoFocus: Efficient Multi-Scale Inference
1. FocusPixels: Small objects in low resolution
2. FocusChips: 贪心, mid resolution
3. Re-sclaed version of FocusChips: Detections on crops high-resolution




